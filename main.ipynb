{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerceptronLearning:\n",
    "    def __init__(self, input_size, learning_rate=0.01, num_epochs=100, reg_lambda=0.01, activation_func='step'):\n",
    "        self.weights = np.random.rand(input_size + 1) * 0.01\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_epochs = num_epochs\n",
    "        self.regularization_lambda = reg_lambda\n",
    "        self.activation_function = activation_func\n",
    "\n",
    "    def activation(self, x):\n",
    "        if self.activation_function == 'step':\n",
    "            return 1 if x >= 0 else 0\n",
    "        elif self.activation_function == 'sigmoid':\n",
    "            return 1 / (1 + np.exp(-x))\n",
    "        elif self.activation_function == 'tanh':\n",
    "            return np.tanh(x)\n",
    "        elif self.activation_function == 'relu':\n",
    "            return max(0, x)\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        summation = np.dot(inputs, self.weights[1:]) + self.weights[0]\n",
    "        return self.activation(summation)\n",
    "\n",
    "    def train(self, training_inputs, labels):\n",
    "        for _ in range(self.num_epochs):\n",
    "            for inputs, label in zip(training_inputs, labels):\n",
    "                prediction = self.predict(inputs)\n",
    "                error = label - prediction\n",
    "                self.weights[1:] += self.learning_rate * ((label - prediction) * inputs - self.regularization_lambda * self.weights[1:])\n",
    "                self.weights[0] += self.learning_rate * (label - prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeltaRuleLearning:\n",
    "    def __init__(self, input_size, learning_rate=0.01, num_epochs=100, reg_lambda=0.01, activation_func='step'):\n",
    "        self.weights = np.random.rand(input_size + 1) * 0.01\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_epochs = num_epochs\n",
    "        self.regularization_lambda = reg_lambda\n",
    "        self.activation_function = activation_func\n",
    "\n",
    "    def activation(self, x):\n",
    "        if self.activation_function == 'step':\n",
    "            return 1 if x >= 0 else 0\n",
    "        elif self.activation_function == 'sigmoid':\n",
    "            return 1 / (1 + np.exp(-x))\n",
    "        elif self.activation_function == 'tanh':\n",
    "            return np.tanh(x)\n",
    "        elif self.activation_function == 'relu':\n",
    "            return max(0, x)\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        summation = np.dot(inputs, self.weights[1:]) + self.weights[0]\n",
    "        return self.activation(summation)\n",
    "\n",
    "    def train(self, training_inputs, labels):\n",
    "        for _ in range(self.num_epochs):\n",
    "            for inputs, label in zip(training_inputs, labels):\n",
    "                prediction = self.predict(inputs)\n",
    "                error = label - prediction\n",
    "                self.weights[1:] += self.learning_rate * (error * inputs - self.regularization_lambda * self.weights[1:])\n",
    "                self.weights[0] += self.learning_rate * error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test):\n",
    "    correct = 0\n",
    "    total = len(X_test)\n",
    "    for inputs, label in zip(X_test, y_test):\n",
    "        prediction = model.predict(inputs)\n",
    "        if prediction == label:\n",
    "            correct += 1\n",
    "    accuracy = correct / total\n",
    "    return accuracy\n",
    "\n",
    "iris_data = pd.read_csv(\"iris.data\", header=None, names=[\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\", \"species\"])\n",
    "\n",
    "species_mapping = {\"Iris-setosa\": 0, \"Iris-versicolor\": 1, \"Iris-virginica\": 2}\n",
    "iris_data[\"species\"] = iris_data[\"species\"].map(species_mapping)\n",
    "\n",
    "X_features = iris_data.drop(\"species\", axis=1).values\n",
    "y_target = iris_data[\"species\"].values\n",
    "\n",
    "X_normalized = (X_features - X_features.mean(axis=0)) / X_features.std(axis=0)\n",
    "\n",
    "X_train_data, X_test_data, y_train_labels, y_test_labels = train_test_split(X_normalized, y_target, test_size=0.2, random_state=42)\n",
    "\n",
    "learning_rates_list = [0.001, 0.01, 0.05, 0.1, 0.25, 0.3, 0.5, 1.0]\n",
    "activation_functions_list = ['step', 'sigmoid', 'tanh', 'relu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate: 0.001\n",
      "Activation Function: step\n",
      "Perceptron Accuracy: 0.63\n",
      "==============================\n",
      "Delta Rule Accuracy: 0.63\n",
      "==============================\n",
      "Learning Rate: 0.001\n",
      "Activation Function: sigmoid\n",
      "Perceptron Accuracy: 0.00\n",
      "==============================\n",
      "Delta Rule Accuracy: 0.00\n",
      "==============================\n",
      "Learning Rate: 0.001\n",
      "Activation Function: tanh\n",
      "Perceptron Accuracy: 0.00\n",
      "==============================\n",
      "Delta Rule Accuracy: 0.00\n",
      "==============================\n",
      "Learning Rate: 0.001\n",
      "Activation Function: relu\n",
      "Perceptron Accuracy: 0.33\n",
      "==============================\n",
      "Delta Rule Accuracy: 0.33\n",
      "==============================\n",
      "Learning Rate: 0.010\n",
      "Activation Function: step\n",
      "Perceptron Accuracy: 0.63\n",
      "==============================\n",
      "Delta Rule Accuracy: 0.63\n",
      "==============================\n",
      "Learning Rate: 0.010\n",
      "Activation Function: sigmoid\n",
      "Perceptron Accuracy: 0.30\n",
      "==============================\n",
      "Delta Rule Accuracy: 0.30\n",
      "==============================\n",
      "Learning Rate: 0.010\n",
      "Activation Function: tanh\n",
      "Perceptron Accuracy: 0.30\n",
      "==============================\n",
      "Delta Rule Accuracy: 0.30\n",
      "==============================\n",
      "Learning Rate: 0.010\n",
      "Activation Function: relu\n",
      "Perceptron Accuracy: 0.33\n",
      "==============================\n",
      "Delta Rule Accuracy: 0.33\n",
      "==============================\n",
      "Learning Rate: 0.050\n",
      "Activation Function: step\n",
      "Perceptron Accuracy: 0.43\n",
      "==============================\n",
      "Delta Rule Accuracy: 0.43\n",
      "==============================\n",
      "Learning Rate: 0.050\n",
      "Activation Function: sigmoid\n",
      "Perceptron Accuracy: 0.30\n",
      "==============================\n",
      "Delta Rule Accuracy: 0.30\n",
      "==============================\n",
      "Learning Rate: 0.050\n",
      "Activation Function: tanh\n",
      "Perceptron Accuracy: 0.30\n",
      "==============================\n",
      "Delta Rule Accuracy: 0.30\n",
      "==============================\n",
      "Learning Rate: 0.050\n",
      "Activation Function: relu\n",
      "Perceptron Accuracy: 0.33\n",
      "==============================\n",
      "Delta Rule Accuracy: 0.33\n",
      "==============================\n",
      "Learning Rate: 0.100\n",
      "Activation Function: step\n",
      "Perceptron Accuracy: 0.33\n",
      "==============================\n",
      "Delta Rule Accuracy: 0.33\n",
      "==============================\n",
      "Learning Rate: 0.100\n",
      "Activation Function: sigmoid\n",
      "Perceptron Accuracy: 0.30\n",
      "==============================\n",
      "Delta Rule Accuracy: 0.30\n",
      "==============================\n",
      "Learning Rate: 0.100\n",
      "Activation Function: tanh\n",
      "Perceptron Accuracy: 0.30\n",
      "==============================\n",
      "Delta Rule Accuracy: 0.30\n",
      "==============================\n",
      "Learning Rate: 0.100\n",
      "Activation Function: relu\n",
      "Perceptron Accuracy: 0.33\n",
      "==============================\n",
      "Delta Rule Accuracy: 0.33\n",
      "==============================\n",
      "Learning Rate: 0.250\n",
      "Activation Function: step\n",
      "Perceptron Accuracy: 0.30\n",
      "==============================\n",
      "Delta Rule Accuracy: 0.30\n",
      "==============================\n",
      "Learning Rate: 0.250\n",
      "Activation Function: sigmoid\n",
      "Perceptron Accuracy: 0.30\n",
      "==============================\n",
      "Delta Rule Accuracy: 0.30\n",
      "==============================\n",
      "Learning Rate: 0.250\n",
      "Activation Function: tanh\n",
      "Perceptron Accuracy: 0.30\n",
      "==============================\n",
      "Delta Rule Accuracy: 0.30\n",
      "==============================\n",
      "Learning Rate: 0.250\n",
      "Activation Function: relu\n",
      "Perceptron Accuracy: 0.33\n",
      "==============================\n",
      "Delta Rule Accuracy: 0.33\n",
      "==============================\n",
      "Learning Rate: 0.300\n",
      "Activation Function: step\n",
      "Perceptron Accuracy: 0.30\n",
      "==============================\n",
      "Delta Rule Accuracy: 0.30\n",
      "==============================\n",
      "Learning Rate: 0.300\n",
      "Activation Function: sigmoid\n",
      "Perceptron Accuracy: 0.30\n",
      "==============================\n",
      "Delta Rule Accuracy: 0.30\n",
      "==============================\n",
      "Learning Rate: 0.300\n",
      "Activation Function: tanh\n",
      "Perceptron Accuracy: 0.30\n",
      "==============================\n",
      "Delta Rule Accuracy: 0.30\n",
      "==============================\n",
      "Learning Rate: 0.300\n",
      "Activation Function: relu\n",
      "Perceptron Accuracy: 0.33\n",
      "==============================\n",
      "Delta Rule Accuracy: 0.33\n",
      "==============================\n",
      "Learning Rate: 0.500\n",
      "Activation Function: step\n",
      "Perceptron Accuracy: 0.30\n",
      "==============================\n",
      "Delta Rule Accuracy: 0.30\n",
      "==============================\n",
      "Learning Rate: 0.500\n",
      "Activation Function: sigmoid\n",
      "Perceptron Accuracy: 0.30\n",
      "==============================\n",
      "Delta Rule Accuracy: 0.30\n",
      "==============================\n",
      "Learning Rate: 0.500\n",
      "Activation Function: tanh\n",
      "Perceptron Accuracy: 0.30\n",
      "==============================\n",
      "Delta Rule Accuracy: 0.30\n",
      "==============================\n",
      "Learning Rate: 0.500\n",
      "Activation Function: relu\n",
      "Perceptron Accuracy: 0.33\n",
      "==============================\n",
      "Delta Rule Accuracy: 0.17\n",
      "==============================\n",
      "Learning Rate: 1.000\n",
      "Activation Function: step\n",
      "Perceptron Accuracy: 0.30\n",
      "==============================\n",
      "Delta Rule Accuracy: 0.30\n",
      "==============================\n",
      "Learning Rate: 1.000\n",
      "Activation Function: sigmoid\n",
      "Perceptron Accuracy: 0.30\n",
      "==============================\n",
      "Delta Rule Accuracy: 0.30\n",
      "==============================\n",
      "Learning Rate: 1.000\n",
      "Activation Function: tanh\n",
      "Perceptron Accuracy: 0.30\n",
      "==============================\n",
      "Delta Rule Accuracy: 0.30\n",
      "==============================\n",
      "Learning Rate: 1.000\n",
      "Activation Function: relu\n",
      "Perceptron Accuracy: 0.33\n",
      "==============================\n",
      "Delta Rule Accuracy: 0.33\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "for lr in learning_rates_list:\n",
    "    for activation_func in activation_functions_list:\n",
    "        print(f\"Learning Rate: {lr:.3f}\\nActivation Function: {activation_func}\")\n",
    "\n",
    "        perceptron_model = PerceptronLearning(input_size=X_normalized.shape[1], learning_rate=lr, activation_func=activation_func)\n",
    "        perceptron_model.train(X_train_data, y_train_labels)\n",
    "        perceptron_accuracy = evaluate_model(perceptron_model, X_test_data, y_test_labels)\n",
    "        print(f\"Perceptron Accuracy: {perceptron_accuracy:.2f}\")\n",
    "\n",
    "        print(\"=\" * 30)  # Separating each combination with '='\n",
    "\n",
    "        delta_rule_model = DeltaRuleLearning(input_size=X_normalized.shape[1], learning_rate=lr, activation_func=activation_func)\n",
    "        delta_rule_model.train(X_train_data, y_train_labels)\n",
    "        delta_rule_accuracy = evaluate_model(delta_rule_model, X_test_data, y_test_labels)\n",
    "        print(f\"Delta Rule Accuracy: {delta_rule_accuracy:.2f}\")\n",
    "\n",
    "        print(\"=\" * 30)  # Separating each combination with '='"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
